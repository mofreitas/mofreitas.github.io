:source-highlighter: pygments
:stem:
:toc:
:icons: font

= Processamento digital de imagens - Resolução Exercícios
Matheus Oliveira de Freitas <matheusoliveirarn@hotmail.com>

== Introdução

Este site se destina a apresentação da solução dos exercícios propostos na disciplina de Processamento Digital de Imagens (DCA0445) disponibilizado pelo Departamento de Engenharia de Computação e Automação da UFRN e ministrado pelo professor Agostinho Brito, cujo curso se encontra disponível em <https://agostinhobritojr.github.io/tutorial/pdi/>.

Todos os exercícios a seguir foram desenvolvidos em C++, juntamente com a biblioteca OpenCV <https://opencv.org/>, compilados usando o _Makefile_ disponibilizado no site do curso. Para compilar e executar os códigos precisamos usar os seguintes comandos:

[source,bash]
----
$ make <nome_arquivo>
$ ./<nome_arquivo> <nome_da_imagem_ou_video>
----

:sectnums:
== Manipulando pixels em uma imagem

Neste tópico vemos como abrir e exibir uma imagem, além de acessar e modificar seus pixels, usando as ferramentas acima.

=== Exercício *_Regiões_*

Usando exemplos/pixels.cpp como referência, foi implementado um algorítmo que recebe uma imagem (passando-a para escala de cinza) e inverte as cores de uma região definida pelas coordenadas de dois vértices P1 e P2. O resultado do algorítmo pode ser visto abaixo.
 
[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char **argv)
{
  Mat image;
  image = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);

  namedWindow("imagem_original", WINDOW_AUTOSIZE);
  imshow("imagem_original", image);
  waitKey();

  int x1, y1, x2, y2;

  cout << "Digite as coordenadas ponto P1 <x y>:" << endl;
  cin >> x1 >> y1;

  cout << "Digite as coordenadas ponto P2 <x y>:" << endl;
  cin >> x2 >> y2;

  //Verifica se cada ponto está dentro dos limites da imagem
  if (x1 != x2 || y1 != y2)
  {
    if (x1 >= 0 && x2 < image.rows && x2 >= 0 && x1 < image.rows)
    {
      if (y1 >= 0 && y2 < image.cols && y2 >= 0 && y1 < image.cols)
      {
        int inicio_x, fim_x, inicio_y, fim_y;

        if (x1 < x2)
        {
          inicio_x = x1;
          fim_x = x2;
        }
        else
        {
          inicio_x = x2;
          fim_x = x1;
        }

        if (y1 < y2)
        {
          inicio_y = y1;
          fim_y = y2;
        }
        else
        {
          inicio_y = y2;
          fim_y = y1;
        }

        //Aplica o efeito de negativo em cada pixel da imagem
        for (int x = inicio_x; x < fim_x; x++)
        {
          for (int y = inicio_y; y < fim_y; y++)
          {
            image.at<uchar>(x, y) = 255 - image.at<uchar>(x, y);
          }
        }

        namedWindow("imagem_negativa", WINDOW_AUTOSIZE);
        imshow("imagem_negativa", image);
        waitKey();
        return 0;
      }
    }
  }

  cout << "Pontos fora dos limites" << endl;
  return 0;
}
----

[#img-regioes]
.Resultado da execução do programa regions.cpp 
image::imagens/figura1.png[Resultado]

=== Exercício *_Troca de regiões_*

Utilizando o programa exemplos/pixels.cpp como referência, foi implementado um programa que troca as regiões da imagem (convertida em tons de cinza) fornecida. Nesse exemplo foi explorado o uso de uma função disponível no OpenCV para extrair regiões de uma imagem e outra que permite a cópia de uma Matriz `Mat` em outra.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  //Divide a imagem original em 4 regiões com tamanho (imagem.rows/2, imagem.cols/2)
  Mat imagem = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  Mat q1 = imagem(Rect(0, 0, imagem.rows / 2, imagem.cols / 2));
  Mat q2 = imagem(Rect(0, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2));
  Mat q3 = imagem(Rect(imagem.rows / 2, 0, imagem.rows / 2, imagem.cols / 2));
  Mat q4 = imagem(Rect(imagem.rows / 2, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2));

  namedWindow("imagem_original", WINDOW_AUTOSIZE);
  imshow("imagem_original", imagem);
  waitKey();

  //Cria matrix com mesmo tamanho da imagem original
  Mat imagemtrocada(imagem.rows, imagem.cols, imagem.type());

  //Copia os quadrantes dentro das novas regiões
  q4.copyTo(imagemtrocada(Rect(0, 0, imagem.rows / 2, imagem.cols / 2)));
  q3.copyTo(imagemtrocada(Rect(0, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2)));
  q2.copyTo(imagemtrocada(Rect(imagem.rows / 2, 0, imagem.rows / 2, imagem.cols / 2)));
  q1.copyTo(imagemtrocada(Rect(imagem.rows / 2, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2)));

  namedWindow("imagem_trocada", WINDOW_AUTOSIZE);
  imshow("imagem_trocada", imagemtrocada);
  waitKey();
  return 0;
}
----

[#img-trocaregioes]
.Resultado da execução do programa trocaregioes.cpp
image::imagens/figura2.png[Resultado]

== Preenchendo regiões

Nessa seção aprendemos sobre o algorítmo _floodfill_, usado para preencher regiões, e o aplicamos em um programa que contabiliza as bolhas e as bolas brancas em uma imagem de fundo preto.

=== Exercício *_labeling_* (1º Parte)

Esse problema ocorre porque a cor de cada pixel da imagem é composta por 8 bits (ou 256 valores), portanto não dá para atribuir uma valor maior que 255 aos pixels da matriz. Para resolver isso, poderíamos atribuir uma cor para cada tipo de objeto (bolhas e bolas) em vez de uma cor diferente para cada objeto.

=== Exercício *_labeling_* (2º Parte)

A partir do labeling.cpp, o algorítmo de contagem foi aprimorado, levando em consideração objetos com mais de um buraco e excluindo as bolhas que tocam a borda da contagem. Abaixo podemos ver o código e o resultado de sua execução:

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <stack>

using namespace cv;
using namespace std;

struct posicao
{
  int x;
  int y;
};

Mat imagem;

void floodfill(int x, int y, int cor_atual, int nova_cor)
{
  stack<posicao> pintar;

  posicao inicial;
  inicial.x = x;
  inicial.y = y;

  pintar.push(inicial);

  while (!pintar.empty())
  {
    posicao posicao_atual = pintar.top();
    pintar.pop();
    imagem.at<uchar>(posicao_atual.x, posicao_atual.y) = nova_cor;

    //Verifica os 4- vizinhos do ponto
    if (posicao_atual.x - 1 >= 0 && imagem.at<uchar>(posicao_atual.x - 1, posicao_atual.y) == cor_atual)
    {
      pintar.push({posicao_atual.x - 1, posicao_atual.y});
    }
    if (posicao_atual.y - 1 >= 0 && imagem.at<uchar>(posicao_atual.x, posicao_atual.y - 1) == cor_atual)
    {
      pintar.push({posicao_atual.x, posicao_atual.y - 1});
    }
    if (posicao_atual.x + 1 < imagem.rows && imagem.at<uchar>(posicao_atual.x + 1, posicao_atual.y) == cor_atual)
    {
      pintar.push({posicao_atual.x + 1, posicao_atual.y});
    }
    if (posicao_atual.y + 1 < imagem.cols && imagem.at<uchar>(posicao_atual.x, posicao_atual.y + 1) == cor_atual)
    {
      pintar.push({posicao_atual.x, posicao_atual.y + 1});
    }
  }
}

int main(int, char **)
{

  int cor = 1;
  int bolhas = 0, bolas = 0;

  imagem = imread("bolhas.png", CV_LOAD_IMAGE_GRAYSCALE);
  if (!imagem.data)
    cout << "nao abriu bolhas.png" << endl;

  imshow("Imagem original", imagem);
  waitKey();

  //Percorrendo bordas superiores e inferiores e eliminando bolhas juntas delas
  for (int y = 0; y < imagem.cols; y++)
  {
    if (imagem.at<uchar>(0, y) == 255)
    {
      floodfill(0, y, 255, 0);
    }
    if (imagem.at<uchar>(imagem.rows - 1, y) == 255)
    {
      floodfill(imagem.rows - 1, y, 255, 0);
    }
  }

  //Percorrendo bordas laterais e eliminando bolhas juntas delas
  for (int x = 0; x < imagem.rows; x++)
  {
    if (imagem.at<uchar>(x, 0) == 255)
    {
      floodfill(x, 0, 255, 0);
    }
    if (imagem.at<uchar>(x, imagem.cols - 1) == 255)
    {
      floodfill(x, imagem.cols - 1, 255, 0);
    }
  }

  imshow("Removendo bolhas das bordas", imagem);
  waitKey();

  //Colore as bolhas e bolas de cinza
  for (int x = 0; x < imagem.rows; x++)
  {
    for (int y = 0; y < imagem.cols; y++)
    {
      if (imagem.at<uchar>(x, y) == 255)
      {
        floodfill(x, y, 255, cor);
        cor++;
      }
    }
  }

  imshow("Destacando bolhas e bolas", imagem);
  waitKey();

  //Pinta o lado de fora do quadro de branco, assim lado interno das bolhas permanecerá preto, facilitando sua localização
  floodfill(0, 0, 0, 255);

  //Procura bolhas (bolas pretas dentro de bolhas de outra cor)
  for (int x = 0; x < imagem.rows; x++)
  {
    for (int y = 0; y < imagem.cols; y++)
    {
      if (imagem.at<uchar>(x, y) == 0)
      {
        //Verifica se a bola preta está dentro de outro objeto (não branco)
        if (imagem.at<uchar>(x, y - 1) != 255)
        {
          //Caso positivo, incrementa o número de bolhas e pinta de branco
          bolhas++;
          floodfill(x, y, 0, 255);
          floodfill(x, y - 1, imagem.at<uchar>(x, y - 1), 255);
        }
        else
        {
          //Se não, apenas pinta de branco, tornando-o parte do fundo (o que pode acontece caso uma bolha tenha 2 buracos)
          floodfill(x, y, 0, 255);
        }
      }
    }
  }

  cout << "Bolhas: " << bolhas << endl;
  imshow("Bolas", imagem);
  waitKey();

  //Com todas as bolhas retiradas, procuram-se as bolas
  for (int x = 0; x < imagem.rows; x++)
  {
    for (int y = 0; y < imagem.cols; y++)
    {
      //Se a cor do ponto for diferente da do fundo, já que todas as bolhas foram retiradas, só pode ser um bola
      if (imagem.at<uchar>(x, y) != 255)
      {
        bolas++;
        floodfill(x, y, imagem.at<uchar>(x, y), 255);
      }
    }
  }

  cout << "Bolas: " << bolas << endl;
  imshow("Resultado final", imagem);
  waitKey();

  return 0;
}
----

[#img-labeling]
.Etapas da execução e resultado do programa labeling.cpp
image::imagens/figura32.png[Resultado]

== Manipulação de histogramas

Essa seção abordou a manipulação de histogramas e a captura de videos no OpenCV.

=== Exercício *_Equalize_*

Utilizando o programa exemplos/histogram.cpp como referência, implementamos um código que realiza a equalização dos quadros (convertidos para tons de cinza) que compõem o vídeo. Abaixo, temos o código e em seguida a comparação entre uma imagem sem tratamento e a equalizada.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  int des_altura_hist = 64;
  int des_largura_hist = 256;
  int tam_hist = 256;
  float range[] = {0, 256};
  const float *histrange = {range};

  VideoCapture video;
  Mat quadro, histograma, histograma_eq, quadro_gray;

  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout << "Video não está aberto" << endl;
    return -1;
  }

  while (true)
  {
    video >> quadro;

    //Converte quadro para tons de cinza
    cvtColor(quadro, quadro_gray, CV_BGR2GRAY);
    calcHist(&quadro_gray, 1, 0, Mat(), histograma, 1, &tam_hist, &histrange);

    int novos_tons[des_largura_hist] = {0};

    //Este loop percorre o histograma calculando o histrograma acumulado, calculando e
    //armazenando no vetor novos_tons os novos tons que os valores antigos devem assumir:
    //novos_tons[tom_antigo] = tom_novo
    int soma = 0;
    for (int i = 0; i < tam_hist; i++)
    {
      soma += histograma.at<float>(i);
      novos_tons[i] = soma * 255.0 / quadro_gray.total();
    }

    Mat resultado(quadro_gray.rows, quadro_gray.cols, CV_8U);

    //Aplica os novos tons no frame, equalizando a imagem
    for (int i = 0; i < quadro_gray.rows; i++)
    {
      for (int j = 0; j < quadro_gray.cols; j++)
      {
        resultado.at<uchar>(i, j) = novos_tons[quadro_gray.at<uchar>(i, j)];
      }
    }

    //Calcula histograma equalizado
    calcHist(&resultado, 1, 0, Mat(), histograma_eq, 1, &tam_hist, &histrange);

    //Cria matriz para o desenho do histograma
    Mat des_hist_original(des_altura_hist, des_largura_hist, CV_8U, Scalar(0));
    Mat des_hist_equalizado(des_altura_hist, des_largura_hist, CV_8U, Scalar(0));

    //Normaliza os histogramas de 0 a 64
    normalize(histograma, histograma, 0, des_hist_original.rows, NORM_MINMAX, -1, Mat());
    normalize(histograma_eq, histograma_eq, 0, des_hist_equalizado.rows, NORM_MINMAX, -1, Mat());

    //Desenha os histogramas
    for (int i = 0; i < des_largura_hist; i++)
    {
      line(des_hist_original,
           Point(i, des_altura_hist),
           Point(i, des_altura_hist - cvRound(histograma.at<float>(i))),
           Scalar(255), 1, 8, 0);
      line(des_hist_equalizado,
           Point(i, des_altura_hist),
           Point(i, des_altura_hist - cvRound(histograma_eq.at<float>(i))),
           Scalar(255), 1, 8, 0);
    }

    des_hist_original.copyTo(quadro_gray(Rect(0, 0, des_largura_hist, des_altura_hist)));
    des_hist_equalizado.copyTo(resultado(Rect(0, 0, des_largura_hist, des_altura_hist)));

    imshow("original", quadro_gray);
    imshow("equalizado", resultado);
    if (waitKey(30) == 27)
      break;
  }
}
----

[#img-equalize1]
.Comparação entre a saída inalterada e a equalizada
image::imagens/figura4.png[Resultado]

Apesar da equalização evidenciar os detalhes escondidos na imagem original, a imagem ficou distorcida por causa do efeito do falso contorno, uma vez que ao passar pelo processo de equalização, os tons dos pixels se distanciaram.

=== Exercício *_motiondetector_*

Nesse exercício, ainda com base no programa exemplos/histogram.cpp, foi implementado uma algorítmo que detecta movimentos. Isso é feito calculando a diferença relativa entre o histograma atual e o anterior do canal verde da imagem. Caso a diferença ultrapasse um limite, que pode ser definido pelo programador, então uma bola vermelha é desenhada no canto superior direto, indicando movimento.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  int des_altura_hist = 64;
  int des_largura_hist = 256;

  //limite da diferença entre histogramas, servindo como gatilho para
  //detecção
  int limite = 15;      

  VideoCapture video;
  Mat frame;

  //É criado vetor para armazenar componentes RGB
  vector<Mat> componentes_rgb;

  //Armazenam histograma do frame passado e do atual
  Mat hist_passado;

  //Intervalo do histograma
  float range[] = {0, 256};
  const float *histRange = {range};
  int tamanho_histograma = 256;

  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout << "Falha na abertura" << endl;
    return (-1);
  }

  int largura = video.get(CV_CAP_PROP_FRAME_WIDTH);

  namedWindow("Video", 1);
  while (true)
  {
    Mat histG, histG_norm;
    video >> frame;

    //Separa a imagem colorida em 3 canais
    split(frame, componentes_rgb);

    //Calcula histograma da componente verde
    calcHist(&componentes_rgb[1], 1, 0, Mat(), histG, 1, &tamanho_histograma, &histRange);

    //Cria matriz para o desenho do histograma
    Mat des_hist_atual(des_altura_hist, des_largura_hist, CV_8UC3, Scalar(0, 0, 0));

    //Normaliza o histograma da cor verde de 0 a 64
    normalize(histG, histG_norm, 0, des_hist_atual.rows, NORM_MINMAX, -1, Mat());

    //Calcula erro relativo médio
    if (!hist_passado.empty())
    {
      double erro_verde = 0.0;

      //Compara cada posição do histograma atual como antigo
      for (int i = 0; i < tamanho_histograma; i++)
      {
        if (histG.at<float>(i) != 0)
        {
          erro_verde += abs((histG.at<float>(i) - hist_passado.at<float>(i)) / histG.at<float>(i));
        }
      }

      //Desenha um circulo vermelho caso detecte movimento
      if (erro_verde > limite)
      {
        circle(frame, Point(largura - 20, 20), 10, Scalar(0, 0, 255), CV_FILLED);
      }

      //Desenha os histogramas
      for (int i = 0; i < des_largura_hist; i++)
      {
        line(des_hist_atual,
             Point(i, des_altura_hist),
             Point(i, des_altura_hist - cvRound(histG_norm.at<float>(i))),
             Scalar(255, 255, 255), 1, 8, 0);
      }
    }

    //Copia histograma no frame
    des_hist_atual.copyTo(frame(Rect(0, 0, des_largura_hist, des_altura_hist)));

    imshow("Video", frame);
    if (waitKey(30) == 27)
      break;

    histG.copyTo(hist_passado);
  }

  return 0;
}
----

[#img-motiondetection]
.Resultado do programa motiondetection.cpp
image::imagens/figura5.png[Resultado]

== Filtragem no domínio espacial I

Nessa seção aprendemos a usar a função filter2D para a realização da convolução digital entre uma imagem e uma máscara.

=== Exercício *_laplgauss_*

Usando o programa exemplos/filtroespacial.cpp como base, adicionamos a opção de aplicar o filtro do laplaciano após aplicar o gaussiano na imagem pressionando a letra `f`. Para isso, definimos `mask` como o gaussiano e atribuimos o valor verdadeiro a variável `lapgauss`. Quando o programa vai aplicar o filtro selecionado, se `lapgauss` for verdadeiro, o filtro laplaciano é aplicado logo após o gaussiano. Quando outro modo é selecionado, a variável `lapgauss` assume o valor falso e, consequentemente, apenas o filtro selecionado é aplicado.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m)
{
  for (int i = 0; i < m.size().height; i++)
  {
    for (int j = 0; j < m.size().width; j++)
    {
      cout << m.at<float>(i, j) << ",";
    }
    cout << endl;
  }
}

void menu()
{
  cout << "\npressione a tecla para ativar o filtro: \n"
          "a - calcular modulo\n"
          "m - media\n"
          "g - gauss\n"
          "v - vertical\n"
          "h - horizontal\n"
          "l - laplaciano\n"
          "esc - sair\n";
}

int main(int argvc, char **argv)
{
  VideoCapture video;
  float media[] = {1, 1, 1,
                   1, 1, 1,
                   1, 1, 1};
  float gauss[] = {1, 2, 1,
                   2, 4, 2,
                   1, 2, 1};
  float horizontal[] = {-1, 0, 1,
                        -2, 0, 2,
                        -1, 0, 1};
  float vertical[] = {-1, -2, -1,
                      0, 0, 0,
                      1, 2, 1};
  float laplacian[] = {0, -1, 0,
                       -1, 4, -1,
                       0, -1, 0};

  Mat cap, frame, frame32f, frameFiltered;
  Mat mask(3, 3, CV_32F), mask1;
  Mat result, result1;
  double width, height, min, max;
  int absolut;
  char key;

  //Variável que indica se o filtro lapgauss está ativado
  bool lapgauss = false;

  video.open("video6.mp4");
  if (!video.isOpened())
    return -1;
  width = video.get(CV_CAP_PROP_FRAME_WIDTH);
  height = video.get(CV_CAP_PROP_FRAME_HEIGHT);
  std::cout << "largura=" << width << "\n";
  ;
  std::cout << "altura =" << height << "\n";
  ;

  namedWindow("filtroespacial", 1);

  mask = Mat(3, 3, CV_32F, media);
  scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
  swap(mask, mask1);
  absolut = 1; // calcs abs of the image

  menu();
  for (;;)
  {
    video >> cap;
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
    frame.convertTo(frame32f, CV_32F);

    //Se o filtro lapgauss estiver ativado, o programa aplica a máscara do laplaciano após aplicar
    //a máscara gaussiana (que foi definida abaixo). Caso contrário, apenas aplica a máscara selecionada.
    if (lapgauss)
    {
      Mat frameFilteredTemp, mask2(3, 3, CV_32F, laplacian);
      filter2D(frame32f, frameFilteredTemp, frame32f.depth(), mask, Point(1, 1), 0);
      filter2D(frameFilteredTemp, frameFiltered, frameFilteredTemp.depth(), mask2, Point(1, 1), 0);
    }
    else
    {
      filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1, 1), 0);
    }

    if (absolut)
    {
      frameFiltered = abs(frameFiltered);
    }
    frameFiltered.convertTo(result, CV_8U);

    imshow("filtroespacial", result);
    key = (char)waitKey(30);
    if (key == 27)
      break; // esc pressed!

    switch (key)
    {
    case 'a':
      menu();
      absolut = !absolut;
      lapgauss = false;
      break;
    case 'm':
      menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = false;
      break;
    case 'g':
      menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1 / 16.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = false;
      break;
    case 'h':
      menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      lapgauss = false;
      break;
    case 'v':
      menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      lapgauss = false;
      break;
    case 'l':
      menu();
      mask = Mat(3, 3, CV_32F, laplacian);
      printmask(mask);
      lapgauss = false;
      break;
    //Adiciona o filtro laplgauss ao programa
    case 'f':
      menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1 / 16.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = true;
      break;
    default:
      break;
    }
  }
  return 0;
}
----

[#img-lapgauss]
.Comparação entre o laplaciano de uma imagem (acima) e o laplaciano do gaussiano (abaixo)
image::imagens/figura6.png[Resultado]

Podemos ver que depois de aplicar o laplaciano do gaussiano as bordas estão menos evidentes. Isso acontece porque ao aplicar o filtro gaussiano, borramos a imagem deixando as bordas mais suaves. Como o laplaciano evidencia as bordas, se elas estiverem borradas, essas mudanças de tonalidade serão menos destacadas.

== Filtragem no domínio espacial II

Nesta seção aprendemos sobre a execução do efeito _tilt-shift_ usando técnicas de processamento digital de imagens. Também foram apresentados funções para a soma e multiplicação de matrizes.

=== Exercicio *_tiltshift_*

Utilizando o programa exemplos/addweighted.cpp como referência, implementamos um programa para a realização do _tilt-shift_ em uma imagem colorida cujo centro, região de decaimento e posição vertical do efeito podem ser alterados por meio de _sliders_. Para a realização desse efeito, foram criadas duas matrizes cujos valores do eixo x foram dados pela seguinte equação:

stem:[f(x) = -0.5 * (tanh((x - centro + l1) / d) - tanh((x - centro + l2) / d)]

TIP: Declarar pelo menos uma das váriáveis usadas dentro do stem:[tanh()] como `float` para que o argumento não seja arredondado. 

Em que `centro` indica o centro da região em foco, `l1` e `l2` os limites dessa região e `d` o quão suave será a transição entre a imagem focada e a borrada.

A matriz resultante desse cálculo é usada para ponderar a imagem sem efeito, e sua inversa stem:[1-f(x)] para ponderar a imagem borrada. Em seguida, ambas são somadas, criando o efeito do _tilt-shift_.

[source, cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

float l1 = -100, l2 = 50, d = 6, centro = 100;

int matriz_media_tam = 7;
int altura, largura;

int slider_altura = 0;
int slider_altura_max = 100;

int slider_decaimento = 0;
int slider_decaimento_max = 100;

int slider_deslocamento = 0;
int slider_deslocamento_max = 100;

Mat imagem, imagem_borrada;

char TrackbarName[50];

void aplicar_Efeito();

void on_trackbar_deslocamento(int, void *)
{
  //O centro é definido pela posição do slider, de forma que
  //0 - topo imagem e 100 -> fundo imagem
  centro = slider_deslocamento * altura / 100;

  aplicar_Efeito();
}

void on_trackbar_altura(int, void *)
{
  //O slider da altura define a distância de l1 e l2 do centro do tilt-shift
  int alt = altura * slider_altura / 100;
  l1 = -alt / 2;
  l2 = alt / 2;

  aplicar_Efeito();
}

void on_trackbar_decaimento(int, void *)
{
  d = slider_decaimento;

  aplicar_Efeito();
}

void aplicar_Efeito()
{
  Mat ponderada(altura, largura, CV_32FC3);
  Mat ponderada_negativa(altura, largura, CV_32FC3);

  cout << "centro: " << centro << 
          ", l1: " << l1 << 
          ", l2: " << l2 << 
          ", decaimento: " << d << endl;

  for (int i = 0; i < altura; i++)
  {    
    float fx = 0.0;
    //Como a função não é definida para d = 0, caso isso ocorra, é atribuido um valor
    //pequeno para d (d=0.01), o que deixa a transição entre 0 e 1 quase abrupta
    if (d != 0)
    {
      //função utilizada para ponderar as imagens
      fx = -0.5 * (tanh((i - centro + l1) / d) - tanh((i - centro + l2) / d));
    }
    else{
      fx = -0.5 * (tanh((i - centro + l1) / 0.01) - tanh((i - centro + l2) / 0.01));
    }

    //O tilt shift é aplicado em cada camada da imagem RGB
    for (int j = 0; j < largura; j++)
    {
      ponderada.at<Vec3f>(i, j)[0] = fx;
      ponderada.at<Vec3f>(i, j)[1] = fx;
      ponderada.at<Vec3f>(i, j)[2] = fx;
      ponderada_negativa.at<Vec3f>(i, j)[0] = 1.0 - fx;
      ponderada_negativa.at<Vec3f>(i, j)[1] = 1.0 - fx;
      ponderada_negativa.at<Vec3f>(i, j)[2] = 1.0 - fx;
    }
  }

  Mat resultado, res1, res2;

  //Cada imagem é multiplicada por sua respectiva matriz ponderada
  multiply(imagem, ponderada, res1);
  multiply(imagem_borrada, ponderada_negativa, res2);

  //As matrizes ponderadas são somadas
  addWeighted(res1, 1, res2, 1, 0, resultado);

  resultado.convertTo(resultado, CV_8UC3);

  imshow("tiltshift", resultado);
}

int main(int argvc, char **argv)
{
  //A másca de média, para borramento, é criada
  float media[matriz_media_tam * matriz_media_tam];
  for (int i = 0; i < matriz_media_tam; i++)
  {
    for (int j = 0; j < matriz_media_tam; j++)
    {
      media[i * matriz_media_tam + j] = 1.0 / (matriz_media_tam * matriz_media_tam);
    }
  }
  Mat masc_media(matriz_media_tam, matriz_media_tam, CV_32F, media);

  vector<Mat> canais;

  imagem = imread(argv[1]);
  imagem.convertTo(imagem, CV_32FC3);

  //O filtro do borramento é aplicado em cada canal separadamente
  split(imagem, canais);

  filter2D(canais[0], canais[0], canais[0].depth(), masc_media, Point(3, 3), 0);
  filter2D(canais[1], canais[1], canais[1].depth(), masc_media, Point(3, 3), 0);
  filter2D(canais[2], canais[2], canais[2].depth(), masc_media, Point(3, 3), 0);

  merge(canais, imagem_borrada);

  largura = imagem.cols;
  altura = imagem.rows;

  namedWindow("tiltshift", 1);

  //Criando os sliders
  sprintf(TrackbarName, "Altura x %d", slider_altura_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &slider_altura,
                 slider_altura_max,
                 on_trackbar_altura);
  on_trackbar_altura(slider_altura, 0);

  sprintf(TrackbarName, "Decaimento x %d", slider_decaimento_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &slider_decaimento,
                 slider_decaimento_max,
                 on_trackbar_decaimento);
  on_trackbar_decaimento(slider_decaimento, 0);

  sprintf(TrackbarName, "Deslocamento x %d", slider_deslocamento_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &slider_deslocamento,
                 slider_deslocamento_max,
                 on_trackbar_deslocamento);
  on_trackbar_deslocamento(slider_deslocamento, 0);

  aplicar_Efeito();

  waitKey(0);
  return 0;
}
----

[#img-tiltshift]
.Comparação entre imagem sem (acima) e com (abaixo) o efeito do tilt-shift
image::imagens/figura71.png[Resultado]

=== Exercicio *_tiltshiftvideo_*

Ainda usando exemplos/addweighted.cpp como base, foi criado um programa que aplica o efeito de _tilt-shift_ e _stop motion_ em um vídeo colorido. Para isso, além de efetuar os mesmos procedimentos do exercício anterior para o _tilt-shift_, foi colocado um laço que descarta `aceleracao` frames do video antes de processar um frame, criando o efeito de _stop motion_. 

[source, cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int matriz_media_tam = 7;

int main(int argvc, char **argv)
{
  VideoCapture video;
  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout << "Erro ao abrir video" << endl;
    return -1;
  }

  int largura = video.get(CV_CAP_PROP_FRAME_WIDTH);
  int altura = video.get(CV_CAP_PROP_FRAME_HEIGHT);

  //Inicializa e preenche a máscara de média
  float media[matriz_media_tam * matriz_media_tam];
  for (int i = 0; i < matriz_media_tam; i++)
  {
    for (int j = 0; j < matriz_media_tam; j++)
    {
      media[i * matriz_media_tam + j] = 1.0 / (matriz_media_tam * matriz_media_tam);
    }
  }

  Mat masc_media(matriz_media_tam, matriz_media_tam, CV_32F, media);

  //Inicializa mascaras do ponderamento
  Mat ponderada(altura, largura, CV_32FC3);
  Mat ponderada_negativa(altura, largura, CV_32FC3);

  int centro = 6*altura / 10, l1 = -70, l2 = 70, aceleracao = 10;
  float d = 30;

  cout << "centro: " << centro << 
          ", l1: " << l1 << 
          ", l2: " << l2 << 
          ", decaimento: " << d << 
          ", aceleração " << aceleracao << endl;

  for (int i = 0; i < altura; i++)
  {
    //Eliminando caso de divisão por 0
    float fx = 0.0;
    if (d != 0)
    {
      //Formula de ponderação
      fx = -0.5 * (tanh((i - centro + l1) / d) - tanh((i - centro + l2) / d));
    }

    //Criação das matrizes de ponderamento
    for (int j = 0; j < largura; j++)
    {
      ponderada.at<Vec3f>(i, j)[0] = fx;
      ponderada.at<Vec3f>(i, j)[1] = fx;
      ponderada.at<Vec3f>(i, j)[2] = fx;
      ponderada_negativa.at<Vec3f>(i, j)[0] = 1.0 - fx;
      ponderada_negativa.at<Vec3f>(i, j)[1] = 1.0 - fx;
      ponderada_negativa.at<Vec3f>(i, j)[2] = 1.0 - fx;
    }
  }

  Mat imagem, imagem_borrada;

  while (true)
  {
    //Descarta aceleracao quadros
    for (int i = 0; i < aceleracao; i++)
    {
      video >> imagem;
    }

    imagem.convertTo(imagem, CV_32FC3);

    //Separa a imagem nos 3 canais, aplica o efeito do borramento e as junta em seguida
    vector<Mat> canais;
    split(imagem, canais);

    filter2D(canais[0], canais[0], canais[0].depth(), masc_media, Point(3, 3), 0);
    filter2D(canais[1], canais[1], canais[1].depth(), masc_media, Point(3, 3), 0);
    filter2D(canais[2], canais[2], canais[2].depth(), masc_media, Point(3, 3), 0);

    merge(canais, imagem_borrada);

    Mat resultado, res1, res2;

    //Multiplica matrizes pelo respectivo ponderamento
    multiply(imagem, ponderada, res1);
    multiply(imagem_borrada, ponderada_negativa, res2);

    //Soma das matrizes
    addWeighted(res1, 1, res2, 1, 0, resultado);

    resultado.convertTo(resultado, CV_8UC3);

    imshow("tiltshift", resultado);
    
    //Tempo para mostrar cada quadro foi aumentado para melhorar a
    //visualização do stop motion
    if (waitKey(50) == 27)
      break;
  }

  return 0;
}
----

[#img-videotiltshift]
.Aplicação do tilt-shift e do stop motion em um video
image::imagens/figura8.png[Resultado]

== Filtragem no domínio da frequência

Nessa seção aprendemos a passar imagens do domínio espacial para o domínio da frequência (e vice-versa) utilizando a Transformada discreta de Fourier e como podemos usar filtros nesse domínio.

=== Exercício *_filtro homomórfico_*

Usando o programa exemplos/dft.cpp como base, implementamos o filtro homomórfico stem:[H(u, v)] que tem o objetivo de corrigir a iluminação de uma imagem em tons de cinza. Ele foi construído usando a fórmula abaixo:

stem:[H(u, v) = (\gamma_H - \gamma_L)(1 - \exp{-c({D(u, v)^{2}}/D_{0}^2)}) + \gamma_L]

Em que stem:[\gamma_L, \gamma_H, D_0] e stem:[c] são as constantes que definem o comportamento do filtro em função da distância do seu centro stem:[D(u, v)].

[#img-filtrohomomorfico]
.Filtro homomórfico gerado com parâmetros usados no programa abaixo.
image::imagens/figura91.png[Resultado]

Para aplicá-lo, primeiramente redimensionamos a imagem para que sua altura e largura sejam potência de 2 e preenchemos o espaço extra com zeros (_padding_) o que possibilita o uso da FFT sem afetar a imagem. Em seguida, efetuamos a operação de `log` na imagem (tanto na parte real como complexa) somada em um para evitar o cálculo de stem:[log(0)]. Então realizamos a Tranformada de Fourier, deslocamos o espectro, multiplicamos o filtro com o espectro e então fazemos a operação inversa. Por fim, efetuamos o `exp` na imagem e a normalizamos para exibição.

[source, cpp]
----
#include <iostream>
#include <cmath>
#include <opencv2/opencv.hpp>
#include <opencv2/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>

//Valores escolhidos esperimentalmente
#define gH 1.7
#define gL 0.6
#define c 0.3
#define d0 7

using namespace cv;
using namespace std;

// troca os quadrantes da imagem da DFT
void deslocaDFT(Mat& image ){
  Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para
  // evitar cópias de tamanho desigual
  image = image(Rect(0, 0, image.cols & -2, image.rows & -2));
  int cx = image.cols/2;
  int cy = image.rows/2;

  // reorganiza os quadrantes da transformada
  // A B   ->  D C
  // C D       B A
  A = image(Rect(0, 0, cx, cy));
  B = image(Rect(cx, 0, cx, cy));
  C = image(Rect(0, cy, cx, cy));
  D = image(Rect(cx, cy, cx, cy));

  // A <-> D
  A.copyTo(tmp);  D.copyTo(A);  tmp.copyTo(D);

  // C <-> B
  C.copyTo(tmp);  B.copyTo(C);  tmp.copyTo(B);
}

int main(int argc, char** argv){
  Mat imaginaryInput, complexImage;
  Mat padded, filter, filter_print;
  Mat image, tmp;
  Mat_<float> zeros;
  vector<Mat> planos, filtros, dfts;

  int dft_M, dft_N;

  image = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  imshow("filtrada", image);
  waitKey();
  
  // identifica os tamanhos otimos para
  // calculo do FFT
  dft_M = getOptimalDFTSize(image.rows);
  dft_N = getOptimalDFTSize(image.cols);

  // realiza o padding da imagem
  copyMakeBorder(image, padded, 0,
                 dft_M - image.rows, 0,
                 dft_N - image.cols,
                 BORDER_CONSTANT, Scalar::all(0));

  // prepara a matriz complexa e preenche com 0
  imaginaryInput = Mat(padded.size(), CV_32FC1, Scalar(0));
  
  //Trasforma padded em float
  padded.convertTo(padded, CV_32F);
  
  normalize(padded, padded, 0.0, 1.0, NORM_MINMAX);
  
  //Soma ambas as componentes com 1 para evitar a operação ln(0)
  cv::log(padded + 1, padded);
  cv::log(imaginaryInput + 1, imaginaryInput);  

  //Concatena plano real e imaginário para realizar a DFT
  planos.push_back(padded);
  planos.push_back(imaginaryInput);

  merge(planos, complexImage);

  // Construindo a função de transferência (filtro frequencial) com o
  // mesmo tamanho e tipo da matriz complexa
  filter = Mat((dft_M & -2), (dft_N & -2), CV_32FC2, Scalar(0, 0));

  // Preenche o filtro homomórfico com os valores dadod pela função
  for(int i=0; i< dft_M; i++){
    for(int j=0; j < dft_N; j++){
      float h = (float) (gH - gL)*(1.0 - exp(-c*(pow(abs(i-dft_M/2)+abs(j-dft_N/2), 2)/pow(d0, 2)))) + gL;
      filter.at<Vec2f>(i, j)[0] = h;
      filter.at<Vec2f>(i, j)[1] = h;
    }
  }

  split(filter, filtros);
  normalize(filtros[0], filter_print, 0.0, 1.0, CV_MINMAX);
  imshow("filtro", filter_print);
  waitKey();

  // Efetua a filtragem
  dft(complexImage, complexImage);
  deslocaDFT(complexImage);
  mulSpectrums(complexImage,filter,complexImage,0);
  deslocaDFT(complexImage);
  idft(complexImage, complexImage, DFT_SCALE);

  cv::exp(complexImage,complexImage);  

  planos.clear();
  split(complexImage, planos);

  // normaliza a parte real para exibicao
  normalize(planos[0], tmp, 0.0, 1.0, CV_MINMAX);
  imshow("imagem_final", tmp);
  waitKey();
  return 0;
}
----

[#img-aplicacaohomomorfico]
.Comparação entre uma imagem antes e depois da aplicação do filtro homomórfico.
image::imagens/figura9.png[Resultado]

Após a aplicação do filtro, percebemos que o brilho da imagem está mais equilibrado.

== Detecção de bordas com o algoritmo de Canny

Nessa seção, vimos a implementação do detecctor de bordas de Canny funciona e como usá-lo no _OpenCV_.

=== Exercício *_cannypoints_*

Usando os programa exemplos/canny.cpp e exemplos/pontilhismo.cpp como base, implementamos um algoritmo que gera um efeito pontilhista em uma imagem fornecida usando o algoritmo de Canny para aumentar sua qualidade. Isso foi feito desenhando círculos menores (dois pixels de raio em comparação com os cinco usados na geração da imagem pontilhista inicial) em cima das posições que o algoritmo indicou como borda.

[source, cpp]
----
#include <iostream>
#include "opencv2/opencv.hpp"
#include <algorithm>
#include <vector>
#include <ctime>
#include <numeric>

using namespace std;
using namespace cv;

#define STEP 4
#define JITTER 3
#define RAIO 5
#define RAIO_PEQUENO 2

int main(int argc, char **argv)
{
  int width, height, limite_inferior = 80;
  int x, y;
  vector<int> xrange, yrange;
  vector<Vec6i> pontos;
  Mat points, image, border, image_bw;
  Vec3b gray;

  image = imread(argv[1], CV_LOAD_IMAGE_COLOR);

  cvtColor(image, image_bw, CV_BGR2GRAY);

  width = image.size().width;
  height = image.size().height;

  //Aplica o algoritmo de canny na imagem
  Canny(image_bw, border, limite_inferior, 3 * limite_inferior);
  imshow("bordas_canny", border);
  waitKey();

  //Obtem imagem pontilhista
  xrange.resize(height / STEP);
  yrange.resize(width / STEP);

  iota(xrange.begin(), xrange.end(), 0);
  iota(yrange.begin(), yrange.end(), 0);

  //Realiza amostragem dos pontos
  for (uint i = 0; i < xrange.size(); i++)
  {
    xrange[i] = xrange[i] * STEP + STEP / 2;
  }

  for (uint i = 0; i < yrange.size(); i++)
  {
    yrange[i] = yrange[i] * STEP + STEP / 2;
  }

  points = Mat(height, width, CV_8UC3, Scalar(255, 255, 255));

  random_shuffle(xrange.begin(), xrange.end());

  for (auto i : xrange)
  {
    random_shuffle(yrange.begin(), yrange.end());
    for (auto j : yrange)
    {
      x = i + rand() % (2 * JITTER) - JITTER + 1;
      y = j + rand() % (2 * JITTER) - JITTER + 1;

      //Impede o algoritmo de pegar pontos além dos limites da imagem
      if (x >= height)
      {
        x = height - 1;
      }
      if (y >= width)
      {
        y = width - 1;
      }

      gray = image.at<Vec3b>(x, y);
      circle(points,
             cv::Point(y, x),
             RAIO,
             Scalar(gray[0], gray[1], gray[2]),
             -1,
             CV_AA);
    }
  }

  imshow("imagem_pontilhista", points);
  waitKey();

  //Percorre matriz em busca da borda gerada pelo algoritmo de canny para
  //desenhar pontos pequenos
  for (int i = 0; i < height; i++)
  {
    for (int j = 0; j < width; j++)
    {
      if (border.at<uchar>(i, j) != 0)
      {
        //Armazena a cor origina do ponto, bem como sua posição na
        //estrutura Vec6i, que armazena 6 inteiros
        gray = image.at<Vec3b>(i, j);
        pontos.push_back(Vec6i(j, i, gray[0], gray[1], gray[2], 0));
      }
    }
  }

  random_shuffle(pontos.begin(), pontos.end());

  //Desenha pontos pequenos na imagem
  Scalar cor;
  for (int i = 0; i < pontos.size(); i++)
  {
    Point p(pontos.at(i)[0], pontos.at(i)[1]);
    cor = Scalar(pontos.at(i)[2], pontos.at(i)[3], pontos.at(i)[4]);
    circle(points,
           p,
           RAIO_PEQUENO,
           cor,
           -1,
           CV_AA);
  }

  imshow("imagem_pontilhista_corrigida", points);
  waitKey();

  imwrite("cannyborders.png", points);
  return 0;
}
----

[#img-pontilhismomelhor]
.Imagem pontilhista antes e depois do processo de melhora na qualidade.
image::imagens/figura10.png[Resultado]

== Quantização vetorial com _k-means_

Nessa seção, aprendemos sobre o funcionamento desse algoritmo de agrupamento e sua utilização no _OpenCV_

=== Exercício *_kmeans_*

Com base no programa kmeans.cpp, fizemos um programa que executa `nRodadas` vezes o algoritmo _k-means_ em uma imagem iniciando os centros de forma aleatória. 

[source, cpp]
----
#include <opencv2/opencv.hpp>
#include <cstdlib>
#include <vector>
#include <iostream>
#include <GraphicsMagick/Magick++.h> //Biblioteca responsável pela geração do GIF

using namespace std;
using namespace cv;

int main( int argc, char** argv ){
  Magick::InitializeMagick(NULL);
  int nClusters = 6;
  Mat rotulos;
  int nRodadas = 1;
  int nExecucoes = 10;
  Mat centros;

  if(argc!=3){
	  exit(0);
  }
  
  //Efetua leitura da imagem
  Mat img = imread( argv[1], CV_LOAD_IMAGE_COLOR);
  Mat samples(img.rows * img.cols, 3, CV_32F);

  //Insere cada pixel da matriz da imagem em um vetor
  for( int y = 0; y < img.rows; y++ ){
    for( int x = 0; x < img.cols; x++ ){
      for( int z = 0; z < 3; z++){
        samples.at<float>(y + x*img.rows, z) = img.at<Vec3b>(y,x)[z];
	    }
	  }
  }
  
  //Executa o kmeans nExecucoes vezes, inserindo-os no vetor rotulada
  vector<Mat> rotulada(nExecucoes,  Mat(img.size(), img.type()) );
  vector<Magick::Image> criarGif;
  for(int i = 0; i<nExecucoes; i++){      
    kmeans(samples,
          nClusters,
          rotulos,
          TermCriteria(CV_TERMCRIT_ITER|CV_TERMCRIT_EPS, 10000, 0.0001),
          nRodadas,
          KMEANS_RANDOM_CENTERS,
          centros );

    for( int y = 0; y < img.rows; y++ ){
      for( int x = 0; x < img.cols; x++ ){ 
        int indice = rotulos.at<int>(y + x*img.rows,0);
        rotulada.at(i).at<Vec3b>(y,x)[0] = (uchar) centros.at<float>(indice, 0);
        rotulada.at(i).at<Vec3b>(y,x)[1] = (uchar) centros.at<float>(indice, 1);
        rotulada.at(i).at<Vec3b>(y,x)[2] = (uchar) centros.at<float>(indice, 2);
      }
    }

    imshow( "Imagem Clusterizada", rotulada.at(i) );
    waitKey(50);

    //Converte a imagem de cv:Mat para Magick::Image, definindo que cada quadro 
    //da animação terá duração de 500ms
    criarGif.push_back(Magick::Image(img.cols, 
                                      img.rows,
                                      "BGR",
                                      Magick::StorageType::CharPixel, 
                                      (char *)rotulada.at(i).data));
    criarGif.back().animationDelay(50);
  }

  //Gera o gif, colocando-o no arquivo "saidaKmeans.gif"
  Magick::writeImages(criarGif.begin(), criarGif.end(), "saidaKmeans.gif");
}
----

No fim é gerado um GIF animado para compararmos os resultados de cada iteração. Isso foi possivel por meio da instalação do _GraphicMagick_ por meio da linha de comando abaixo e da modificação do arquivo link:programs/Makefile[Makefile] para que código pudesse ser compilado.

[source, bash]
----
$ sudo apt install libgraphicsmagick++1-dev 
----

[#img-saidakmeans]
.Saída das `nRodadas` do kmeans.
image::imagens/figura11.gif[Resultado]

Como os centros dos agrupamentos são escolhidos de forma aleatória, esses pontos mudam a cada rodada, o que pode gerar imagens diferentes, conforme vemos no GIF acima.

:!sectnums:
