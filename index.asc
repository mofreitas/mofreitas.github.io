:source-highlighter: pygments
:stem:
:toc:

= Processamento digital de imagens - Resolução Exercícios
Matheus Oliveira de Freitas <matheusoliveirarn@hotmail.com>

== Introdução

Este site se destina a apresentação da solução dos exercícios propostos na disciplina de Processamento Digital de Imagens (DCA0445) disponibilizado pelo Departamento de Computação de Automação da UFRN e ministrado pelo professor Agostinho Brito, cujo curso se encontra disponível em <https://agostinhobritojr.github.io/tutorial/pdi/>.

Todos os exercícios a seguir foram desenvolvidos em C++, juntamente com a biblioteca OpenCV <https://opencv.org/>, compilados usando o _Makefile_ disponibilizado no site do curso. Para compilar e executar os códigos precisamos usar os seguintes comandos:

[source,bash]
----
$ make <nome_arquivo>
$ ./<nome_arquivo> <nome_da_imagem_ou_video>
----

:sectnums:
== Manipulando pixels em uma imagem

Neste tópico vemos como podemos abrir, acessar e modificar seus pixels, e exibir uma imagem usando as ferramentas acima.

=== Exercício *_Regiões_*

Usando exemplos/pixels.cpp como referência, foi implementado um algorítmo que recebe uma imagem (passando-a para escala de cinza) e inverte as cores de uma região definida pelas coordenadas de dois vértices P1 e P2. O resultado do algorítimo pode ser visto abaixo.
 
[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char **argv)
{
  Mat image;
  image = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);

  namedWindow("imagem_original", WINDOW_AUTOSIZE);
  imshow("imagem_original", image);
  waitKey();

  int x1, y1, x2, y2;

  cout << "Digite as coordenadas ponto P1 <x y>:" << endl;
  cin >> x1 >> y1;

  cout << "Digite as coordenadas ponto P2 <x y>:" << endl;
  cin >> x2 >> y2;

  //Verifica se cada ponto está dentro dos limites da imagem
  if (x1 != x2 || y1 != y2)
  {
    if (x1 >= 0 && x2 < image.rows && x2 >= 0 && x1 < image.rows)
    {
      if (y1 >= 0 && y2 < image.cols && y2 >= 0 && y1 < image.cols)
      {
        int inicio_x, fim_x, inicio_y, fim_y;

        if (x1 < x2)
        {
          inicio_x = x1;
          fim_x = x2;
        }
        else
        {
          inicio_x = x2;
          fim_x = x1;
        }

        if (y1 < y2)
        {
          inicio_y = y1;
          fim_y = y2;
        }
        else
        {
          inicio_y = y2;
          fim_y = y1;
        }

        //Aplica o efeito de negativo em cada pixel da imagem
        for (int x = inicio_x; x < fim_x; x++)
        {
          for (int y = inicio_y; y < fim_y; y++)
          {
            image.at<uchar>(x, y) = 255 - image.at<uchar>(x, y);
          }
        }

        namedWindow("imagem_negativa", WINDOW_AUTOSIZE);
        imshow("imagem_negativa", image);
        waitKey();
        return 0;
      }
    }
  }

  cout << "Pontos fora dos limites" << endl;
  return 0;
}
----

[#img-regioes]
.Resultado da execução do programa regions.cpp 
image::imagens/figura1.png[Resultado]

=== Exercício *_Troca de regiões_*

Utilizando o programa exemplos/pixels.cpp como referência, foi implementado um programa que troca as regiões da imagem (convertida em tons de cinza) fornecida. Nesse exemplo foi explorado o uso de uma função disponível no OpenCV para extrair regiões de uma imagem e outra que permite a cópia de uma Matriz `Mat` em outra.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  //Divide a imagem original em 4 regiões com tamanho (imagem.rows/2, imagem.cols/2)
  Mat imagem = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  Mat q1 = imagem(Rect(0, 0, imagem.rows / 2, imagem.cols / 2));
  Mat q2 = imagem(Rect(0, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2));
  Mat q3 = imagem(Rect(imagem.rows / 2, 0, imagem.rows / 2, imagem.cols / 2));
  Mat q4 = imagem(Rect(imagem.rows / 2, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2));

  namedWindow("imagem_original", WINDOW_AUTOSIZE);
  imshow("imagem_original", imagem);
  waitKey();

  //Cria matrix com mesmo tamanho da imagem original
  Mat imagemtrocada(imagem.rows, imagem.cols, imagem.type());

  //Copia os quadrantes dentro das novas regiões
  q4.copyTo(imagemtrocada(Rect(0, 0, imagem.rows / 2, imagem.cols / 2)));
  q3.copyTo(imagemtrocada(Rect(0, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2)));
  q2.copyTo(imagemtrocada(Rect(imagem.rows / 2, 0, imagem.rows / 2, imagem.cols / 2)));
  q1.copyTo(imagemtrocada(Rect(imagem.rows / 2, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2)));

  namedWindow("imagem_trocada", WINDOW_AUTOSIZE);
  imshow("imagem_trocada", imagemtrocada);
  waitKey();
  return 0;
}
----

[#img-trocaregioes]
.Resultado da execução do programa trocaregioes.cpp
image::imagens/figura2.png[Resultado]

== Preenchendo regiões

Nessa seção aprendemos sobre o algorítimo _floodfill_, usado para preencher regiões, e o aplicamos em programa que contabiliza as bolhas e as bolas brancas em uma imagem de fundo preto.

=== Exercício *_labeling_* (1º Parte)

Esse problema ocorre porque a cor de cada pixel da imagem é composta por 8 bits (ou 256 valores), portanto não dá para atribuir uma valor maior que 255 aos pixels da matriz. Para resolver isso, poderíamos atribuir uma cor para cada tipo de objeto (bolhas e bolas) em vez de uma cor diferente para cada objeto.

=== Exercício *_labeling_* (2º Parte)

A partir do labeling.cpp, o algorítimo de contagem foi aprimorado, levando em consideração obejtos com mais de um buraco e excluindo as bolhas que tocam a borda da contagem. Abaixo podemos ver o código e o resultado de sua execução:

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <stack>

using namespace cv;
using namespace std;

struct posicao
{
  int x;
  int y;
};

Mat imagem;

void floodfill(int x, int y, int cor_atual, int nova_cor)
{
  stack<posicao> pintar;

  posicao inicial;
  inicial.x = x;
  inicial.y = y;

  pintar.push(inicial);

  while (!pintar.empty())
  {
    posicao posicao_atual = pintar.top();
    pintar.pop();
    imagem.at<uchar>(posicao_atual.x, posicao_atual.y) = nova_cor;

    //Verifica os 4- vizinhos do ponto
    if (posicao_atual.x - 1 >= 0 && imagem.at<uchar>(posicao_atual.x - 1, posicao_atual.y) == cor_atual)
    {
      pintar.push({posicao_atual.x - 1, posicao_atual.y});
    }
    if (posicao_atual.y - 1 >= 0 && imagem.at<uchar>(posicao_atual.x, posicao_atual.y - 1) == cor_atual)
    {
      pintar.push({posicao_atual.x, posicao_atual.y - 1});
    }
    if (posicao_atual.x + 1 < imagem.rows && imagem.at<uchar>(posicao_atual.x + 1, posicao_atual.y) == cor_atual)
    {
      pintar.push({posicao_atual.x + 1, posicao_atual.y});
    }
    if (posicao_atual.y + 1 < imagem.cols && imagem.at<uchar>(posicao_atual.x, posicao_atual.y + 1) == cor_atual)
    {
      pintar.push({posicao_atual.x, posicao_atual.y + 1});
    }
  }
}

int main(int, char **)
{

  int cor = 1;
  int bolhas = 0, bolas = 0;

  imagem = imread("bolhas.png", CV_LOAD_IMAGE_GRAYSCALE);
  if (!imagem.data)
    cout << "nao abriu bolhas.png" << endl;

  imshow("Imagem original", imagem);
  waitKey();

  //Percorrendo bordas superiores e inferiores e eliminando bolhas juntas delas
  for (int y = 0; y < imagem.cols; y++)
  {
    if (imagem.at<uchar>(0, y) == 255)
    {
      floodfill(0, y, 255, 0);
    }
    if (imagem.at<uchar>(imagem.rows - 1, y) == 255)
    {
      floodfill(imagem.rows - 1, y, 255, 0);
    }
  }

  //Percorrendo bordas laterais e eliminando bolhas juntas delas
  for (int x = 0; x < imagem.rows; x++)
  {
    if (imagem.at<uchar>(x, 0) == 255)
    {
      floodfill(x, 0, 255, 0);
    }
    if (imagem.at<uchar>(x, imagem.cols - 1) == 255)
    {
      floodfill(x, imagem.cols - 1, 255, 0);
    }
  }

  imshow("Removendo bolhas das bordas", imagem);
  waitKey();

  //Colore as bolhas e bolas de cinza
  for (int x = 0; x < imagem.rows; x++)
  {
    for (int y = 0; y < imagem.cols; y++)
    {
      if (imagem.at<uchar>(x, y) == 255)
      {
        floodfill(x, y, 255, cor);
        cor++;
      }
    }
  }

  imshow("Destacando bolhas e bolas", imagem);
  waitKey();

  //Pinta o lado de fora do quadro de branco, assim lado interno das bolhas permanecerá preto, facilitando sua localização
  floodfill(0, 0, 0, 255);

  //Procura bolhas (bolas pretas dentro de bolhas de outra cor)
  for (int x = 0; x < imagem.rows; x++)
  {
    for (int y = 0; y < imagem.cols; y++)
    {
      if (imagem.at<uchar>(x, y) == 0)
      {
        //Verifica se a bola preta está dentro de outro objeto (não branco)
        if (imagem.at<uchar>(x, y - 1) != 255)
        {
          //Caso positivo, incrementa o número de bolhas e pinta de branco
          bolhas++;
          floodfill(x, y, 0, 255);
          floodfill(x, y - 1, imagem.at<uchar>(x, y - 1), 255);
        }
        else
        {
          //Se não, apenas pinta de branco, tornando-o parte do fundo (o que pode acontece caso uma bolha tenha 2 buracos)
          floodfill(x, y, 0, 255);
        }
      }
    }
  }

  cout << "Bolhas: " << bolhas << endl;
  imshow("Bolas", imagem);
  waitKey();

  //Com todas as bolhas retiradas, procuram-se as bolas
  for (int x = 0; x < imagem.rows; x++)
  {
    for (int y = 0; y < imagem.cols; y++)
    {
      //Se a cor do ponto for diferente da do fundo, já que todas as bolhas foram retiradas, só pode ser um bola
      if (imagem.at<uchar>(x, y) != 255)
      {
        bolas++;
        floodfill(x, y, imagem.at<uchar>(x, y), 255);
      }
    }
  }

  cout << "Bolas: " << bolas << endl;
  imshow("Resultado final", imagem);
  waitKey();

  return 0;
}
----

[#img-labeling]
.Etapas da execução e resultado do programa labeling.cpp
image::imagens/figura32.png[Resultado]

== Manipulação de histogramas

Essa seção abordou a manipulação de histogramas e a captura de videos no OpenCV.

=== Exercício *_Equalize_*

Utilizando o programa exemplos/histogram.cpp como referência, implementamos um código que realiza a equalização dos quadros (convertidos para tons de cinza) que compõem o vídeo. Abaixo, temos o código e também visualizar os efeitos da equalização em um ambiente escuro.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  int des_altura_hist = 64;
  int des_largura_hist = 256;
  int tam_hist = 256;
  float range[] = {0, 256};
  const float *histrange = {range};

  VideoCapture video;
  Mat quadro, histograma, histograma_eq, quadro_gray;

  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout << "Video não está aberto" << endl;
    return -1;
  }

  while (true)
  {
    video >> quadro;

    //Converte quadro para tons de cinza
    cvtColor(quadro, quadro_gray, CV_BGR2GRAY);
    calcHist(&quadro_gray, 1, 0, Mat(), histograma, 1, &tam_hist, &histrange);

    int novos_tons[des_largura_hist] = {0};

    //Este loop percorre o histograma calculando o histrograma acumulado, calculando e
    //armazenando no vetor novos_tons os novos tons que os valores antigos devem assumir:
    //novos_tons[tom_antigo] = tom_novo
    int soma = 0;
    for (int i = 0; i < tam_hist; i++)
    {
      soma += histograma.at<float>(i);
      novos_tons[i] = soma * 255.0 / quadro_gray.total();
    }

    Mat resultado(quadro_gray.rows, quadro_gray.cols, CV_8U);

    //Aplica os novos tons no frame, equalizando a imagem
    for (int i = 0; i < quadro_gray.rows; i++)
    {
      for (int j = 0; j < quadro_gray.cols; j++)
      {
        resultado.at<uchar>(i, j) = novos_tons[quadro_gray.at<uchar>(i, j)];
      }
    }

    //Calcula histograma equalizado
    calcHist(&resultado, 1, 0, Mat(), histograma_eq, 1, &tam_hist, &histrange);

    //Cria matriz para o desenho do histograma
    Mat des_hist_original(des_altura_hist, des_largura_hist, CV_8U, Scalar(0));
    Mat des_hist_equalizado(des_altura_hist, des_largura_hist, CV_8U, Scalar(0));

    //Normaliza os histogramas de 0 a 64
    normalize(histograma, histograma, 0, des_hist_original.rows, NORM_MINMAX, -1, Mat());
    normalize(histograma_eq, histograma_eq, 0, des_hist_equalizado.rows, NORM_MINMAX, -1, Mat());

    //Desenha os histogramas
    for (int i = 0; i < des_largura_hist; i++)
    {
      line(des_hist_original,
           Point(i, des_altura_hist),
           Point(i, des_altura_hist - cvRound(histograma.at<float>(i))),
           Scalar(255), 1, 8, 0);
      line(des_hist_equalizado,
           Point(i, des_altura_hist),
           Point(i, des_altura_hist - cvRound(histograma_eq.at<float>(i))),
           Scalar(255), 1, 8, 0);
    }

    des_hist_original.copyTo(quadro_gray(Rect(0, 0, des_largura_hist, des_altura_hist)));
    des_hist_equalizado.copyTo(resultado(Rect(0, 0, des_largura_hist, des_altura_hist)));

    imshow("original", quadro_gray);
    imshow("equalizado", resultado);
    if (waitKey(30) == 27)
      break;
  }
}
----

[#img-equalize1]
.Comparação entre a saída inalterada e a equalizada
image::imagens/figura4.png[Resultado]

Apesar da equalização evidenciar os detalhes escondidos na imagem original, quando uma cena tem um histograma estreito, a imagem fica distorcida por causa do efeito do falso contorno, uma vez que os os tons se distanciam depois desse tratamento.

=== Exercício *_motiondetector_*

Nesse exercício, ainda com base no programa exemplos/histogram.cpp, foi implementado uma algorítimo que detecta movimentos. Isso é feito calculando a diferença relativa entre o histograma atual e o anterior do canal verde da imagem. Caso a diferença ultrapasse um limite, que pode ser definido pelo programador, então uma bola vermelha é desenhada no canto superior direto, indicando movimento.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  int des_altura_hist = 64;
  int des_largura_hist = 256;

  //limite da diferença entre histogramas, servindo como gatilho para
  //detecção
  int limite = 15;      

  VideoCapture video;
  Mat frame;

  //É criado vetor para armazenar componentes RGB
  vector<Mat> componentes_rgb;

  //Armazenam histograma do frame passado e do atual
  Mat hist_passado;

  //Intervalo do histograma
  float range[] = {0, 256};
  const float *histRange = {range};
  int tamanho_histograma = 256;

  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout << "Falha na abertura" << endl;
    return (-1);
  }

  int largura = video.get(CV_CAP_PROP_FRAME_WIDTH);

  namedWindow("Video", 1);
  while (true)
  {
    Mat histG, histG_norm;
    video >> frame;

    //Separa a imagem colorida em 3 canais
    split(frame, componentes_rgb);

    //Calcula histograma da componente verde
    calcHist(&componentes_rgb[1], 1, 0, Mat(), histG, 1, &tamanho_histograma, &histRange);

    //Cria matriz para o desenho do histograma
    Mat des_hist_atual(des_altura_hist, des_largura_hist, CV_8UC3, Scalar(0, 0, 0));

    //Normaliza o histograma da cor verde de 0 a 64
    normalize(histG, histG_norm, 0, des_hist_atual.rows, NORM_MINMAX, -1, Mat());

    //Calcula erro relativo médio
    if (!hist_passado.empty())
    {
      double erro_verde = 0.0;

      //Compara cada posição do histograma atual como antigo
      for (int i = 0; i < tamanho_histograma; i++)
      {
        if (histG.at<float>(i) != 0)
        {
          erro_verde += abs((histG.at<float>(i) - hist_passado.at<float>(i)) / histG.at<float>(i));
        }
      }

      //Desenha um circulo vermelho caso detecte movimento
      if (erro_verde > limite)
      {
        circle(frame, Point(largura - 20, 20), 10, Scalar(0, 0, 255), CV_FILLED);
      }

      //Desenha os histogramas
      for (int i = 0; i < des_largura_hist; i++)
      {
        line(des_hist_atual,
             Point(i, des_altura_hist),
             Point(i, des_altura_hist - cvRound(histG_norm.at<float>(i))),
             Scalar(255, 255, 255), 1, 8, 0);
      }
    }

    //Copia histograma no frame
    des_hist_atual.copyTo(frame(Rect(0, 0, des_largura_hist, des_altura_hist)));

    imshow("Video", frame);
    if (waitKey(30) == 27)
      break;

    histG.copyTo(hist_passado);
  }

  return 0;
}
----

[#img-motiondetection]
.Resultado do programa motiondetection.cpp
image::imagens/figura5.png[Resultado]

== Filtragem no domínio espacial I

Nessa seção aprendemos a usar a função filter2D para a realização da convolução digital entre uma imagem e uma máscara.

=== Exercício *_laplgauss_*

Usando o programa exemplos/filtroespacial.cpp como base, adicionamos a opção de aplicar o filtro do laplaciano após aplicar o filtro do gaussiano na imagem apertando a letra `f`. Para isso, definimos `mask` como o gaussiano e atribuimos o valor verdadeiro a variável `lapgauss`. Quando o programa aplica o filtro, ele verifica se `lapgauss` é verdadeiro porém ao aplicar o filtro, aplicando o filtro gaussiano e em seguida o laplaciano caso verdadeiro. Para desativar esse filtro, quando outro modo é selecionado, a variável `lapgauss` assume o valor falso e , consequentemente, os filtros são aplicados normalmente.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m)
{
  for (int i = 0; i < m.size().height; i++)
  {
    for (int j = 0; j < m.size().width; j++)
    {
      cout << m.at<float>(i, j) << ",";
    }
    cout << endl;
  }
}

void menu()
{
  cout << "\npressione a tecla para ativar o filtro: \n"
          "a - calcular modulo\n"
          "m - media\n"
          "g - gauss\n"
          "v - vertical\n"
          "h - horizontal\n"
          "l - laplaciano\n"
          "esc - sair\n";
}

int main(int argvc, char **argv)
{
  VideoCapture video;
  float media[] = {1, 1, 1,
                   1, 1, 1,
                   1, 1, 1};
  float gauss[] = {1, 2, 1,
                   2, 4, 2,
                   1, 2, 1};
  float horizontal[] = {-1, 0, 1,
                        -2, 0, 2,
                        -1, 0, 1};
  float vertical[] = {-1, -2, -1,
                      0, 0, 0,
                      1, 2, 1};
  float laplacian[] = {0, -1, 0,
                       -1, 4, -1,
                       0, -1, 0};

  Mat cap, frame, frame32f, frameFiltered;
  Mat mask(3, 3, CV_32F), mask1;
  Mat result, result1;
  double width, height, min, max;
  int absolut;
  char key;

  //Variável que indica se o filtro lapgauss está ativado
  bool lapgauss = false;

  video.open("video6.mp4");
  if (!video.isOpened())
    return -1;
  width = video.get(CV_CAP_PROP_FRAME_WIDTH);
  height = video.get(CV_CAP_PROP_FRAME_HEIGHT);
  std::cout << "largura=" << width << "\n";
  ;
  std::cout << "altura =" << height << "\n";
  ;

  namedWindow("filtroespacial", 1);

  mask = Mat(3, 3, CV_32F, media);
  scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
  swap(mask, mask1);
  absolut = 1; // calcs abs of the image

  menu();
  for (;;)
  {
    video >> cap;
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
    frame.convertTo(frame32f, CV_32F);

    //Se o filtro lapgauss estiver ativado, o programa aplica a máscara do laplaciano após aplicar
    //a máscara gaussiana (que foi definida abaixo). Caso contrário, apenas aplica a máscara selecionada.
    if (lapgauss)
    {
      Mat frameFilteredTemp, mask2(3, 3, CV_32F, laplacian);
      filter2D(frame32f, frameFilteredTemp, frame32f.depth(), mask, Point(1, 1), 0);
      filter2D(frameFilteredTemp, frameFiltered, frameFilteredTemp.depth(), mask2, Point(1, 1), 0);
    }
    else
    {
      filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1, 1), 0);
    }

    if (absolut)
    {
      frameFiltered = abs(frameFiltered);
    }
    frameFiltered.convertTo(result, CV_8U);

    imshow("filtroespacial", result);
    key = (char)waitKey(30);
    if (key == 27)
      break; // esc pressed!

    switch (key)
    {
    case 'a':
      menu();
      absolut = !absolut;
      lapgauss = false;
      break;
    case 'm':
      menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = false;
      break;
    case 'g':
      menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1 / 16.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = false;
      break;
    case 'h':
      menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      lapgauss = false;
      break;
    case 'v':
      menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      lapgauss = false;
      break;
    case 'l':
      menu();
      mask = Mat(3, 3, CV_32F, laplacian);
      printmask(mask);
      lapgauss = false;
      break;
    //Adiciona o filtro laplgauss ao programa
    case 'f':
      menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1 / 16.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = true;
      break;
    default:
      break;
    }
  }
  return 0;
}
----

[#img-lapgauss]
.Comparação entre o laplaciano de uma imagem (acima) e o laplaciano do gaussiano (abaixo)
image::imagens/figura6.png[Resultado]

Podemos ver que na imagem abaixo as bordas estão menos evidentes. Isso acontece porque ao aplicar o filtro gaussiano, borramos a imagem deixando as bordas mais suaves. Isso afeta o efeito do filtro lapaciano, que apenas evidencia mudanças bruscas de tonalidade (bordas).

== Filtragem no domínio espacial II

Nesta seção aprendemos sobre a execução do efeito _tilt-shift_ usando técnicas de processamento digital de imagens. Também forma apresentados funções para a soma e multiplicação de matrizes.

=== Exercicio *_tiltshift_*

Utilizando o programa exemplos/addweighted.cpp como referência, implementamos um programa para a realização do _tilt-shift_ em uma imagem colorida cujo centro, região de decaimento e posição vertical do efeito podem ser alterados por meio de sliders. Para a realização desse efeito, foram criadas duas matrizes de ponderação usando a seguinte fórmula:

stem:[f(x) = -0.5 * (tanh((x - centro + l1) / 0.01) - tanh((x - centro + l2) / 0.01)]

A matriz resultante desse cálculo foi usada para ponderar a imagem normal e a inversa dela stem:[1-f(x)] para ponderar a imagem borrada. Em seguida ambas foram somada, criando o efeito do _tilt-shift_.

[source, cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

float l1 = -100, l2 = 50, d = 6, centro = 100;

int matriz_media_tam = 5;
int altura, largura;

int slider_altura = 0;
int slider_altura_max = 100;

int slider_decaimento = 0;
int slider_decaimento_max = 100;

int slider_deslocamento = 0;
int slider_deslocamento_max = 100;

Mat imagem, imagem_borrada;

char TrackbarName[50];

void aplicar_Efeito();

void on_trackbar_deslocamento(int, void *)
{
  //O centro é definido pela posição do slider, de forma que
  //0 - topo imagem e 100 -> fundo imagem
  centro = slider_deslocamento * altura / 100;

  aplicar_Efeito();
}

void on_trackbar_altura(int, void *)
{
  //O slider da altura define a distância de l1 e l2 do centro do tilt-shift
  int alt = altura * slider_altura / 100;
  l1 = -alt / 2;
  l2 = alt / 2;

  aplicar_Efeito();
}

void on_trackbar_decaimento(int, void *)
{
  d = slider_decaimento;

  aplicar_Efeito();
}

void aplicar_Efeito()
{
  Mat ponderada(altura, largura, CV_32FC3);
  Mat ponderada_negativa(altura, largura, CV_32FC3);

  cout << "centro: " << centro << 
          ", l1: " << l1 << 
          ", l2: " << l2 << 
          ", decaimento: " << d << endl;

  for (int i = 0; i < altura; i++)
  {    
    float fx = 0.0;
    //Como a função não é definida para d = 0, caso isso ocorra, é atribuido um valor
    //pequeno para d (d=0.01), o que deixa a transição entre 0 e 1 quase abrupta
    if (d != 0)
    {
      //função utilizada para ponderar as imagens
      fx = -0.5 * (tanh((i - centro + l1) / d) - tanh((i - centro + l2) / d));
    }
    else{
      fx = -0.5 * (tanh((i - centro + l1) / 0.01) - tanh((i - centro + l2) / 0.01));
    }

    //A ponderação é feita em cada camada RGB
    for (int j = 0; j < largura; j++)
    {
      ponderada.at<Vec3f>(i, j)[0] = fx;
      ponderada.at<Vec3f>(i, j)[1] = fx;
      ponderada.at<Vec3f>(i, j)[2] = fx;
      ponderada_negativa.at<Vec3f>(i, j)[0] = 1.0 - fx;
      ponderada_negativa.at<Vec3f>(i, j)[1] = 1.0 - fx;
      ponderada_negativa.at<Vec3f>(i, j)[2] = 1.0 - fx;
    }
  }

  Mat resultado, res1, res2;

  //Cada imagem é multiplicada por sua respectiva matriz ponderada
  multiply(imagem, ponderada, res1);
  multiply(imagem_borrada, ponderada_negativa, res2);

  //As matrizes ponderadas são somadas
  addWeighted(res1, 1, res2, 1, 0, resultado);

  resultado.convertTo(resultado, CV_8UC3);

  imshow("tiltshift", resultado);
}

int main(int argvc, char **argv)
{
  //A másca de média, para borramento, é criada
  float media[matriz_media_tam * matriz_media_tam];
  for (int i = 0; i < matriz_media_tam; i++)
  {
    for (int j = 0; j < matriz_media_tam; j++)
    {
      media[i * matriz_media_tam + j] = 1.0 / 25;
    }
  }
  Mat masc_media(matriz_media_tam, matriz_media_tam, CV_32F, media);

  vector<Mat> canais;

  imagem = imread(argv[1]);
  imagem.convertTo(imagem, CV_32FC3);

  //O filtro do borramento é aplicado em cada canal separadamente
  split(imagem, canais);

  filter2D(canais[0], canais[0], canais[0].depth(), masc_media, Point(2, 2), 0);
  filter2D(canais[1], canais[1], canais[1].depth(), masc_media, Point(2, 2), 0);
  filter2D(canais[2], canais[2], canais[2].depth(), masc_media, Point(2, 2), 0);

  merge(canais, imagem_borrada);

  largura = imagem.cols;
  altura = imagem.rows;

  namedWindow("tiltshift", 1);

  //Criando os sliders
  sprintf(TrackbarName, "Altura x %d", slider_altura_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &slider_altura,
                 slider_altura_max,
                 on_trackbar_altura);
  on_trackbar_altura(slider_altura, 0);

  sprintf(TrackbarName, "Decaimento x %d", slider_decaimento_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &slider_decaimento,
                 slider_decaimento_max,
                 on_trackbar_decaimento);
  on_trackbar_decaimento(slider_decaimento, 0);

  sprintf(TrackbarName, "Deslocamento x %d", slider_deslocamento_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &slider_deslocamento,
                 slider_deslocamento_max,
                 on_trackbar_deslocamento);
  on_trackbar_deslocamento(slider_deslocamento, 0);

  aplicar_Efeito();

  waitKey(0);
  return 0;
}
----

[#img-tiltshift]
.Comparação entre imagem sem (acima) e com (abaixo) o efeito do tilt-shift
image::imagens/figura71.png[Resultado]

=== Exercicio *_tiltshiftvideo_*

Ainda usando exemplos/addweighted.cpp como base, foi criado um programa que aplica o efeito de _tilt-shift_ e _stop motion_ em um vídeo colorido. Para isso, além de efetuar os mesmos procedimentos do exercício anteriorpara o _tilt-shift_, foi colocado um laço que descarta `aceleracao` frame do video antes de processar um frame, crinado o efeito de _stop motion_. 

[source, cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int matriz_media_tam = 5;

int main(int argvc, char **argv)
{
  VideoCapture video;
  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout << "Erro ao abrir video" << endl;
    return -1;
  }

  int largura = video.get(CV_CAP_PROP_FRAME_WIDTH);
  int altura = video.get(CV_CAP_PROP_FRAME_HEIGHT);

  //Inicializa e preenche a máscara de média
  float media[matriz_media_tam * matriz_media_tam];
  for (int i = 0; i < matriz_media_tam; i++)
  {
    for (int j = 0; j < matriz_media_tam; j++)
    {
      media[i * matriz_media_tam + j] = 1.0 / 25.0;
    }
  }

  Mat masc_media(matriz_media_tam, matriz_media_tam, CV_32F, media);

  //Inicializa mascaras do ponderamento
  Mat ponderada(altura, largura, CV_32FC3);
  Mat ponderada_negativa(altura, largura, CV_32FC3);

  int centro = altura / 2, l1 = -50, l2 = 50, d = 10, aceleracao = 8;
  cout << "centro: " << centro << 
          ", l1: " << l1 << 
          ", l2: " << l2 << 
          ", decaimento: " << d << 
          ", aceleração " << aceleracao << endl;

  for (int i = 0; i < altura; i++)
  {
    //Eliminando caso de divisão por 0
    float fx = 0.0;
    if (d != 0)
    {
      //Formula de ponderação
      fx = -0.5 * (tanh((i - centro + l1) / d) - tanh((i - centro + l2) / d));
    }

    //Criação das matrizes de ponderamento
    for (int j = 0; j < largura; j++)
    {
      ponderada.at<Vec3f>(i, j)[0] = fx;
      ponderada.at<Vec3f>(i, j)[1] = fx;
      ponderada.at<Vec3f>(i, j)[2] = fx;
      ponderada_negativa.at<Vec3f>(i, j)[0] = 1.0 - fx;
      ponderada_negativa.at<Vec3f>(i, j)[1] = 1.0 - fx;
      ponderada_negativa.at<Vec3f>(i, j)[2] = 1.0 - fx;
    }
  }

  Mat imagem, imagem_borrada;

  while (true)
  {
    //Descarta aceleracao quadros
    for (int i = 0; i < aceleracao; i++)
    {
      video >> imagem;
    }

    imagem.convertTo(imagem, CV_32FC3);

    //Separa a imagem nos 3 canais, aplica o efeito do borramento e as junta em seguida
    vector<Mat> canais;
    split(imagem, canais);

    filter2D(canais[0], canais[0], canais[0].depth(), masc_media, Point(2, 2), 0);
    filter2D(canais[1], canais[1], canais[1].depth(), masc_media, Point(2, 2), 0);
    filter2D(canais[2], canais[2], canais[2].depth(), masc_media, Point(2, 2), 0);

    merge(canais, imagem_borrada);

    Mat resultado, res1, res2;

    //Multiplica matrizes pelo respectivo ponderamento
    multiply(imagem, ponderada, res1);
    multiply(imagem_borrada, ponderada_negativa, res2);

    //Soma das matrizes
    addWeighted(res1, 1, res2, 1, 0, resultado);

    resultado.convertTo(resultado, CV_8UC3);

    imshow("tiltshift", resultado);
    if (waitKey(30) == 27)
      break;
  }

  return 0;
}
----

[#img-videotiltshift]
.Aplicação do tilt-shift e do stop motion em um video
image::imagens/figura8.png[Resultado]

:!sectnums:
